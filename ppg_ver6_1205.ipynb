{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### SVM 로드 -> `ocsvm_loaded`로 사용"
      ],
      "metadata": {
        "id": "2ItEIe1JQL3p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7CZPXVRP5jo"
      },
      "outputs": [],
      "source": [
        "# SVM 로드\n",
        "import joblib\n",
        "\n",
        "loaded = joblib.load(\"ppg_ocsvm_model_1203.joblib\")\n",
        "ocsvm_loaded = loaded[\"model\"]\n",
        "scaler_loaded = loaded[\"scaler\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import scipy.signal as signal\n",
        "from scipy.interpolate import interp1d\n",
        "import math\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "vAMLkzajQVSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams['figure.figsize'] = (12, 4)\n",
        "plt.rcParams['axes.grid'] = True"
      ],
      "metadata": {
        "id": "DJWJQ4bFQj1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `prepare_time_axis(df)`\n",
        "```\n",
        "입력: df(컬럼에 t_us 포함)\n",
        "출력: df(컬럼에 time_s 추가), fs_est(추정 주파수)\n",
        "```"
      ],
      "metadata": {
        "id": "XxkOHhcVQbGN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "def prepare_time_axis(df):\n",
        "    \"\"\"pd의 df를 인자로 받아서 copy후 time_s컬럼에 기존 t_us (마이크로초 단위)를 초단위 변환\"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    # t_us: microseconds → seconds\n",
        "    df[\"time_s\"] = df[\"t_us\"] * 1e-6\n",
        "\n",
        "    # 샘플링 주파수 추정\n",
        "    t = df[\"time_s\"].values\n",
        "    dt = np.diff(t) # np.diff(t)는 연속된 원소의 차이를 구하는 함수\n",
        "    # df는 연속된 시간 값들의 차이(Δt)만 모아놓은 1차원 배열이 됨\n",
        "\n",
        "    dt_med = np.median(dt) # 간격들의 중앙값 활용\n",
        "    fs_est = 1.0 / dt_med # 추정된fs = (1 / 샘플 간격)\n",
        "\n",
        "    print(f\"추정된 샘플링 주파수 ≈ {fs_est:.2f} Hz\")\n",
        "\n",
        "    return df, fs_est"
      ],
      "metadata": {
        "cellView": "form",
        "id": "rxswpx7DQxby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `design_bandpass()`\n",
        "```\n",
        "입력: fs (주파수), low (하한 컷오프(Hz)), high (상한 컷오프(Hz)). order (필터 차수)\n",
        "출력: b, a (bandpass filter 계수)\n",
        "```"
      ],
      "metadata": {
        "id": "AwlyfBryQ2PQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# low_cut  = 0.5   # Hz\n",
        "# high_cut = 6.0   # Hz\n",
        "# order = 2"
      ],
      "metadata": {
        "id": "09ufOf0UQ0RZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "def design_bandpass(fs, low, high, order=2):\n",
        "    \"\"\"샘플링 주파수, 상/하한 컷오프 주파수, 필터 차수(기본 2) 입력받아서,\n",
        "    설계된 대역통과 필터의 계수 반환 -> signal.filtfilt(b, a, x)로 실제 신호에 적용\"\"\"\n",
        "    nyq = 0.5 * fs\n",
        "    low_n  = low / nyq\n",
        "    high_n = high / nyq\n",
        "    b, a = signal.butter(order, [low_n, high_n], btype='band')\n",
        "    return b, a"
      ],
      "metadata": {
        "cellView": "form",
        "id": "GiaVG426RKXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `apply_bandpass()`\n",
        "```\n",
        "입력: df, b, a (필터 계수), ppg_col (필터링 대상 컬럼명, 기본='ppg')\n",
        "출력: df (ppg_filt 컬럼 추가)\n",
        "```"
      ],
      "metadata": {
        "id": "r6SWg1PGRQOn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "def apply_bandpass(df, b, a, ppg_col=\"ppg\"):\n",
        "    \"\"\"컬럼명(ppg)을 전달받아서 실제로 대역폭 필터를 적용해서...\"\"\"\n",
        "    # PPG 신호(df[ppg_col])를 numpy 배열로 가져옴\n",
        "    x = df[ppg_col].values.astype(float)\n",
        "    x_filt = signal.filtfilt(b, a, x)   # filtfilt(b, a, x)로 필터 적용\n",
        "\n",
        "    # 새로운 df 생성, 새 컬럼으로 필터링된 신호를 추가\n",
        "    df_filt = df.copy()\n",
        "    df_filt[ppg_col + \"_filt\"] = x_filt\n",
        "    return df_filt # 새로운 데이터프레임 (ppg_filt 컬럼 추가) 반환"
      ],
      "metadata": {
        "cellView": "form",
        "id": "yQwMdDQeRjoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `detect_systolic_peaks()`\n",
        "```\n",
        "입력: time_s (초 단위 시간축 배열), ppg, fs, min_hr_bpm, max_hr_bpm (심박수 범위, 기본값 설정됨)\n",
        "출력: peaks (peak 인덱스 배열), props (peak 특성(dict))\n",
        "```"
      ],
      "metadata": {
        "id": "orfTgoiVRk0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "def detect_systolic_peaks(time_s, ppg, fs, min_hr_bpm=40, max_hr_bpm=180):\n",
        "    \"\"\"시간 축(초), ppg 신호, 샘플링 주파수, 허용 가능한 최대, 최소 심박수를 입력받고\n",
        "    \"\"\"\n",
        "    # 최대 심박수를 기준으로 peak간의 최소(minimum?) 간격을 설정\n",
        "    min_distance_sec = 60.0 / max_hr_bpm   # Ex. HR이 180이면 60/180 ≈ 최소 간격 0.33s\n",
        "    min_distance_samples = int(min_distance_sec * fs) # 신호는 sample 단위 -> 샘플 개수로 바꿔야\n",
        "    # PPG에서 peak(심박)를 찾을 때, 심박수가 너무 가까이 두 번 찍히는 건 잘못된 peak\n",
        "    # 위의 예제에서 각 beat 사이 간격 = 1/3초 = \"0.33초로 제한\"\n",
        "\n",
        "    # prominence는 대략 signal range의 일부로 설정\n",
        "    # 잡음 peak를 제외하기 위한 임계치? -> 두드러지는 값 설정?\n",
        "    prom = 0.1 * (np.max(ppg) - np.min(ppg))\n",
        "\n",
        "    # signal.find_peaks() 사용하여 봉우리 감지\n",
        "    peaks, props = signal.find_peaks(\n",
        "        ppg,\n",
        "        distance=min_distance_samples,\n",
        "        prominence=prom\n",
        "    )\n",
        "\n",
        "    print(f\"Detected {len(peaks)} systolic peaks.\")\n",
        "    return peaks, props"
      ],
      "metadata": {
        "cellView": "form",
        "id": "M3NcQIRyR8qI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "아래는 수축기 피크 사이를 35샘플로 조정한 `detect_systolic_peak()` 함"
      ],
      "metadata": {
        "id": "j0UJiPSAEIV7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "def detect_systolic_peaks(time_s, ppg, fs, min_hr_bpm=40, max_hr_bpm=180):\n",
        "    \"\"\"시간 축(초), ppg 신호, 샘플링 주파수, 허용 가능한 최대, 최소 심박수를 입력받고\n",
        "    \"\"\"\n",
        "    min_distance_sec = 0.35 # 35개 샘플로 제한\n",
        "    min_distance_samples = int(min_distance_sec * fs)\n",
        "\n",
        "    prom = 0.1 * (np.max(ppg) - np.min(ppg))\n",
        "\n",
        "    # signal.find_peaks() 사용하여 봉우리 감지\n",
        "    peaks, props = signal.find_peaks(\n",
        "        ppg,\n",
        "        distance=min_distance_samples,\n",
        "        prominence=prom\n",
        "    )\n",
        "\n",
        "    print(f\"Detected {len(peaks)} systolic peaks.\")\n",
        "    return peaks, props"
      ],
      "metadata": {
        "cellView": "form",
        "id": "4Hz1bJsUERYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `find_local_valley()`\n",
        "```\n",
        "입력: ppg, center_idx (검색 중심 index = peak idx), search_radius_samples (탐색 반경, 자동 설정)\n",
        "출력: valley_idx\n",
        "```"
      ],
      "metadata": {
        "id": "V_8cHUEjR_Vx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "def find_local_valley(ppg, center_idx, search_radius_samples):\n",
        "    # 신호 범위를 넘기지 않도록 범위 조절\n",
        "    # [center_idx - r, center_idx + r] 구간만 살펴봄\n",
        "    start = max(center_idx - search_radius_samples, 0)\n",
        "    end = min(center_idx + search_radius_samples, len(ppg)-1)\n",
        "    local_segment = ppg[start:end+1]\n",
        "\n",
        "    # 구간에서 최소값 위치 찾기\n",
        "    local_min_idx = np.argmin(local_segment)\n",
        "\n",
        "    # 전체 ppg 기준의 인덱스로 변환\n",
        "    valley_idx = start + local_min_idx\n",
        "    return valley_idx # valley 인덱스 반환"
      ],
      "metadata": {
        "cellView": "form",
        "id": "F9NOdkt8SQp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `find_foot_points()`\n",
        "```\n",
        "입력: time_s, ppg, peak (peak 인덱스 배열), fs\n",
        "출력: start_indices (각 피크의 시작index 리스트), end_indices (각 피크의 끝 index 리스트)\n",
        "```"
      ],
      "metadata": {
        "id": "M2dEjO27SRA4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "def find_foot_points(time_s, ppg, peaks, fs):\n",
        "    \"\"\"\n",
        "    각 peak 이전의 valley만 찾고,\n",
        "    다음 심주기의 시작점 = 현재 심주기의 끝점이 되도록 연속성 보장\n",
        "    \"\"\"\n",
        "    Ts_min, Ts_max = 0.15, 0.26\n",
        "\n",
        "    valleys = []\n",
        "\n",
        "    for i, pk in enumerate(peaks):\n",
        "        Ts_min_samp = int(Ts_min * fs)\n",
        "        Ts_max_samp = int(Ts_max * fs)\n",
        "\n",
        "        # Find valley before peak\n",
        "        start_min = max(pk - Ts_max_samp, 0)\n",
        "        start_max = max(pk - Ts_min_samp, 0)\n",
        "\n",
        "        if start_max <= start_min:\n",
        "            valleys.append(None)\n",
        "        else:\n",
        "            local_seg = ppg[start_min:start_max+1]\n",
        "            local_min_idx = np.argmin(local_seg)\n",
        "            valley_idx = start_min + local_min_idx\n",
        "            valleys.append(valley_idx)\n",
        "\n",
        "    # 각 심주기를 valley[i] → peak[i] → valley[i+1]로 정의\n",
        "    start_indices = []\n",
        "    end_indices = []\n",
        "\n",
        "    for i in range(len(peaks)):\n",
        "        if valleys[i] is None:\n",
        "            start_indices.append(None)\n",
        "            end_indices.append(None)\n",
        "            continue\n",
        "\n",
        "        start_idx = valleys[i]\n",
        "\n",
        "        # 마지막 peak인 경우\n",
        "        if i == len(peaks) - 1:\n",
        "            # 마지막 peak 이후 일정 구간에서 valley 찾기\n",
        "            Te_min_samp = int(0.44 * fs)\n",
        "            Te_max_samp = int(0.74 * fs)\n",
        "            end_min = min(peaks[i] + Te_min_samp, len(ppg)-1)\n",
        "            end_max = min(peaks[i] + Te_max_samp, len(ppg)-1)\n",
        "\n",
        "            if end_max > end_min:\n",
        "                local_seg = ppg[end_min:end_max+1]\n",
        "                local_min_idx = np.argmin(local_seg)\n",
        "                end_idx = end_min + local_min_idx\n",
        "            else:\n",
        "                end_idx = None\n",
        "        else:\n",
        "            # 다음 valley를 end point로 사용\n",
        "            end_idx = valleys[i+1]\n",
        "\n",
        "        start_indices.append(start_idx)\n",
        "        end_indices.append(end_idx)\n",
        "\n",
        "    return start_indices, end_indices"
      ],
      "metadata": {
        "cellView": "form",
        "id": "47k9rDjdSe98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `compute_pulse_width()`, `compute_ab_ratio()`\n",
        "```\n",
        "입력: time_s, ppg, start_idx, peak_idx, end_idx\n",
        "출력: Pw (Pulse Width (float) 또는 None), Ab_over_Aa (float 또는 None)\n",
        "```"
      ],
      "metadata": {
        "id": "fC0xxBcUSfRu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "def compute_pulse_width(time_s, ppg, start_idx, peak_idx, end_idx):\n",
        "    \"\"\"PPG 한 주기에서 Pulse Width(PW) 계산\n",
        "    초단위 시간축 배열, ppg 신호, 주기 시작/끝/수축기 피크 인덱스를 받아서 계산\"\"\"\n",
        "    if start_idx is None or end_idx is None:\n",
        "        return None\n",
        "\n",
        "    v_start = ppg[start_idx]\n",
        "    v_peak  = ppg[peak_idx]\n",
        "    As = v_peak - v_start\n",
        "    if As <= 0: # Peak가 valley보다 낮으면 → 비정상 → None 반환\n",
        "        return None\n",
        "\n",
        "    # valley와 peak 절반 높이 정의\n",
        "    half_level = v_start + As * 0.5\n",
        "\n",
        "    # start_idx → peak_idx 구간 잘라서 seg1으로 정의\n",
        "    seg1 = ppg[start_idx:peak_idx+1]\n",
        "    t1 = time_s[start_idx:peak_idx+1]\n",
        "\n",
        "    # find index where seg1 crosses half_level\n",
        "    try:\n",
        "        # 절반 높이보다 커지는 시점?\n",
        "        idx_before = np.where(seg1 < half_level)[0]\n",
        "        idx_after = np.where(seg1 >= half_level)[0]\n",
        "        # simple approach: first index above half_level\n",
        "        if len(idx_before) > 0 and len(idx_after) > 0:\n",
        "            i1 = idx_after[0] # 딱 절반 높이(half_level까지 올라왔을 때)\n",
        "        else:\n",
        "            i1 = None\n",
        "    except:\n",
        "        i1 = None\n",
        "\n",
        "    # Half-level 하강 시점 찾기\n",
        "    seg2 = ppg[peak_idx:end_idx+1]\n",
        "    t2 = time_s[peak_idx:end_idx+1]\n",
        "\n",
        "    try:\n",
        "        idx_after2 = np.where(seg2 < half_level)[0]\n",
        "        if len(idx_after2) > 0:\n",
        "            i2 = idx_after2[0]\n",
        "        else:\n",
        "            i2 = None\n",
        "    except:\n",
        "        i2 = None\n",
        "\n",
        "    if (i1 is None) or (i2 is None):\n",
        "        return None\n",
        "\n",
        "    # i1, i2가 전부 탐지 되었을 때 list에 저장\n",
        "    t_half1 = t1[i1]\n",
        "    t_half2 = t2[i2]\n",
        "    Pw = t_half2 - t_half1\n",
        "    if Pw <= 0:\n",
        "        return None\n",
        "    return Pw"
      ],
      "metadata": {
        "cellView": "form",
        "id": "qEsbmgfmSo7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "def compute_ab_ratio(time_s, ppg, start_idx, peak_idx, end_idx):\n",
        "    if start_idx is None or end_idx is None:\n",
        "        return None\n",
        "\n",
        "    seg = ppg[start_idx:end_idx+1]\n",
        "    t_seg = time_s[start_idx:end_idx+1]\n",
        "\n",
        "    # second derivative\n",
        "    d1 = np.gradient(seg, np.mean(np.diff(t_seg)))\n",
        "    d2 = np.gradient(d1, np.mean(np.diff(t_seg)))\n",
        "\n",
        "    # we expect 'a' near systolic upstroke, 'b' early diastole\n",
        "    # split segment into two halves as rough approximation\n",
        "    mid_idx = len(seg) // 2\n",
        "\n",
        "    # find max in first half (a-wave)\n",
        "    a_region = d2[:mid_idx]\n",
        "    if len(a_region) == 0:\n",
        "        return None\n",
        "    a_idx_local = np.argmax(a_region)\n",
        "    Aa = a_region[a_idx_local]\n",
        "\n",
        "    # find max in second half (b-wave) - could be smaller\n",
        "    b_region = d2[mid_idx:]\n",
        "    if len(b_region) == 0:\n",
        "        return None\n",
        "    b_idx_local = np.argmax(b_region)\n",
        "    Ab = b_region[b_idx_local]\n",
        "\n",
        "    if Aa == 0:\n",
        "        return None\n",
        "\n",
        "    return Ab / Aa"
      ],
      "metadata": {
        "cellView": "form",
        "id": "YLv1_AqCSxPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `extract_pulse_features()`\n",
        "```\n",
        "입력: df, fs, ppg_col (PPG 컬럼명='ppg_filt), label (라벨 (옵션))\n",
        "출력: features_df (심주기마다 특징값 담긴 DataFrame), (peaks, start_indices, end_indices)\n",
        "```"
      ],
      "metadata": {
        "id": "o_odU0XRSpLk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "def extract_pulse_features(df, fs, ppg_col=\"ppg_filt\", label=None):\n",
        "    time_s = df[\"time_s\"].values\n",
        "    ppg = df[ppg_col].values.astype(float)\n",
        "\n",
        "    peaks, _ = detect_systolic_peaks(time_s, ppg, fs)\n",
        "    start_indices, end_indices = find_foot_points(time_s, ppg, peaks, fs)  # 수정된 함수 사용\n",
        "\n",
        "    feature_rows = []\n",
        "    dropped = 0\n",
        "\n",
        "    for i, pk in enumerate(peaks):\n",
        "        s_idx = start_indices[i]\n",
        "        e_idx = end_indices[i]\n",
        "\n",
        "        # 필터링 조건\n",
        "        if (s_idx is None) or (e_idx is None):\n",
        "            dropped += 1\n",
        "            continue\n",
        "        if s_idx >= pk or pk >= e_idx:\n",
        "            dropped += 1\n",
        "            continue\n",
        "\n",
        "        # 나머지 특징 추출 코드는 동일\n",
        "        t_start = time_s[s_idx]\n",
        "        t_peak = time_s[pk]\n",
        "        t_end = time_s[e_idx]\n",
        "\n",
        "        As = ppg[pk] - ppg[s_idx]\n",
        "        if As <= 0:\n",
        "            dropped += 1\n",
        "            continue\n",
        "\n",
        "        Tc = t_peak - t_start\n",
        "        if Tc < 0.1 or Tc > 0.5:\n",
        "            dropped += 1\n",
        "            continue\n",
        "\n",
        "        Pw = compute_pulse_width(time_s, ppg, s_idx, pk, e_idx)\n",
        "\n",
        "        if i < len(peaks) - 1:\n",
        "            Pi = time_s[peaks[i+1]] - t_peak\n",
        "        else:\n",
        "            Pi = None\n",
        "\n",
        "        if (Pi is not None) and (As > 0):\n",
        "            Pi_over_As = Pi / As\n",
        "        else:\n",
        "            Pi_over_As = None\n",
        "\n",
        "        Ab_over_Aa = compute_ab_ratio(time_s, ppg, s_idx, pk, e_idx)\n",
        "        if Ab_over_Aa is not None and Ab_over_Aa > 3.0:\n",
        "            dropped += 1\n",
        "            continue\n",
        "\n",
        "        feature_rows.append({\n",
        "            \"t_peak\": t_peak,\n",
        "            \"As\": As,\n",
        "            \"Pw\": Pw,\n",
        "            \"Pi_over_As\": Pi_over_As,\n",
        "            \"Tc\": Tc,\n",
        "            \"Ab_over_Aa\": Ab_over_Aa,\n",
        "            \"start_idx\": s_idx,\n",
        "            \"peak_idx\": pk,\n",
        "            \"end_idx\": e_idx,\n",
        "            \"label\": label\n",
        "        })\n",
        "\n",
        "    features_df = pd.DataFrame(feature_rows)\n",
        "    print(f\"{dropped}개의 심주기 오류 발생으로 Drop\")\n",
        "    print(f\"Extracted {len(features_df)} pulses with features.\")\n",
        "\n",
        "    return features_df, (peaks, start_indices, end_indices)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "QYJdAY5GTH9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `extract_pulse_waveforms()`\n",
        "```\n",
        "입력:\n",
        "출력: np array ((N, seq_len) shape의 pulse)\n",
        "```\n",
        "> 심주기 단위로 잘라서 150으로 리샘플링"
      ],
      "metadata": {
        "id": "seawU5LZTIPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "def extract_pulse_waveforms(df_signal, features_df, seq_len=150):\n",
        "    \"\"\"\n",
        "    Extract pulse waveforms using start_idx and end_idx from features_df.\n",
        "    Resample each pulse to fixed length seq_len.\n",
        "    \"\"\"\n",
        "    pulses = []\n",
        "    for _, row in features_df.iterrows():\n",
        "        start_time = int(row[\"start_idx\"])\n",
        "        end_time = int(row[\"end_idx\"])\n",
        "\n",
        "        x = df_signal[\"ppg_filt\"].values[start_time:end_time+1] # if \"ppg_filt\" in df_signal.columns else df_signal[\"ppg_filt_smaf\"].values[start_time:end_time+1]\n",
        "\n",
        "        # Resample to seq_len\n",
        "        old_indices = np.linspace(0, 1, len(x))\n",
        "        new_indices = np.linspace(0, 1, seq_len)\n",
        "        x_resampled = np.interp(new_indices, old_indices, x)\n",
        "        pulses.append(x_resampled)\n",
        "\n",
        "    print(f\"Extracted {len(pulses)} pulses.\")\n",
        "    return np.array(pulses)  # shape: (N, seq_len)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "hZsu8hp0TY9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 시각화 코드 (숨김코드 실행)\n",
        "* `plot_ppg(df, fs, title, duration_sec=8)`: ppg 원 신호 그래프 출력\n",
        "* `plot_filter_response(b, a, fs, title)`: 필터가 억제하는 대역폭 그래프\n",
        "* `plot_before_after(df, col_raw, col_filt, title, duration_sec=8)`: 필터 통과 전후 ppg 그래프"
      ],
      "metadata": {
        "id": "_7zYuKctW4_l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "def plot_ppg(df, fs, title, duration_sec=8):\n",
        "    \"\"\"df, 샘플링 주파수(추정값), 제목, 구간 길이를 인자로 받아서 ppg 그래프 출력\"\"\"\n",
        "    # .values를 활용해 각 컬럼 값들을 numpy 배열로 가져옴\n",
        "    t = df[\"time_s\"].values # 가로축은 시간축\n",
        "    x = df[\"ppg\"].values # 세로축은 ppg 시그널로 plot 생성\n",
        "\n",
        "    t0 = t[0]\n",
        "    # duration_sec을 기준으로 필요한 범위만 선택\n",
        "    mask = (t - t0) <= duration_sec\n",
        "\n",
        "    print(f\"\\nPlotting: {title}\")\n",
        "    # 샘플 개수가 duration_sec × fs 근접해야 정상\n",
        "    print(f\"Using samples = {mask.sum()} (approx {duration_sec} seconds)\")\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(t[mask] - t0, x[mask])\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Time (s)\")\n",
        "    plt.ylabel(\"PPG (raw)\")\n",
        "    plt.show()\n",
        "\n",
        "def plot_filter_response(b, a, fs, title):\n",
        "    \"\"\"구해진 필터 계수 b, a와 샘플링 주파수, 제목을 전달받아서\n",
        "    필터가 어떤 주파수를 통과시키고, 어떤 주파수를 억제하는지 그래프 출력\"\"\"\n",
        "    w, h = signal.freqz(b, a, worN=1024)\n",
        "    freqs = w * fs / (2 * np.pi)\n",
        "\n",
        "    plt.figure(figsize=(8,4))\n",
        "    plt.plot(freqs, 20 * np.log10(np.abs(h)))\n",
        "    plt.title(f\"Frequency Response: {title}\")\n",
        "    plt.xlabel(\"Frequency (Hz)\")\n",
        "    plt.ylabel(\"Magnitude (dB)\")\n",
        "    plt.grid(True)\n",
        "    plt.xlim(0, fs/2)\n",
        "    plt.show()\n",
        "\n",
        "def plot_before_after(df, col_raw, col_filt, title, duration_sec=8):\n",
        "    \"\"\"df, 원본 신호와 필터 통과 신호, 제목, 구간 길이 입력받아서 시각화\"\"\"\n",
        "    t = df[\"time_s\"].values # 시간 컬럼\n",
        "    x_raw  = df[col_raw].values\n",
        "    x_filt = df[col_filt].values\n",
        "\n",
        "    # 시간 배열을 생성하고 시작부터 duration_sec만큼 데이터 선택(mask)\n",
        "    t0 = t[0]\n",
        "    mask = (t - t0) <= duration_sec\n",
        "\n",
        "    print(f\"\\nPlotting before/after for: {title}\")\n",
        "    print(f\"Samples used: {mask.sum()}\")\n",
        "\n",
        "    # 같은 구간에서 원본 신호와 필터 신호를 하나의 그래프에 출력\n",
        "    plt.figure(figsize=(12,5))\n",
        "    plt.plot(t[mask] - t0, x_raw[mask],  label=\"Raw\",  alpha=0.5)\n",
        "    plt.plot(t[mask] - t0, x_filt[mask], label=\"Filtered\", linewidth=2)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Time (s)\")\n",
        "    plt.ylabel(\"PPG\")\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "-i2tA8dXW5aN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CSV 준비"
      ],
      "metadata": {
        "id": "blSTMFqsWi77"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================\n",
        "# 1. File paths\n",
        "# =============================\n",
        "\n",
        "path1 = \"/content/1204_tae_static_1.csv\"\n",
        "path2 = \"/content/1204_tae_static_2.csv\"\n",
        "\n",
        "# =============================\n",
        "# 2. Load CSV\n",
        "# =============================\n",
        "# pd 데이터프레임화\n",
        "df1 = pd.read_csv(path1)\n",
        "df2 = pd.read_csv(path2)\n",
        "\n",
        "print(\"\\ncsv1 head:\")\n",
        "display(df1.head())\n",
        "\n",
        "print(\"\\ncsv2 head:\")\n",
        "display(df2.head())"
      ],
      "metadata": {
        "id": "7cukjJLAWmlf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================\n",
        "# 3. 초 단위 시간축 변환 및 시각화\n",
        "# =============================\n",
        "# (t_us → seconds) + estimate fs\n",
        "# 시간 축 정리 및 샘플링 주파수 추정\n",
        "\n",
        "df1, fs_df1 = prepare_time_axis(df1)\n",
        "df2, fs_df2 = prepare_time_axis(df2)\n",
        "\n",
        "# plot_ppg(df, fs, title, duration_sec=8)\n",
        "plot_ppg(df1, fs_df1, \"csv1 PPG\")\n",
        "plot_ppg(df2, fs_df2, \"csv2 PPG\")"
      ],
      "metadata": {
        "id": "ehNOx8bcWwE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================\n",
        "# design_bandpass() -> 출력은 필터링 계수 a, b\n",
        "# =====================\n",
        "import scipy.signal as signal\n",
        "\n",
        "low_cut  = 0.5   # Hz\n",
        "high_cut = 6.0   # Hz\n",
        "order = 2\n",
        "\n",
        "b_df1, a_df1 = design_bandpass(fs_df1, low_cut, high_cut, order)\n",
        "b_df2, a_df2 = design_bandpass(fs_df2, low_cut, high_cut, order)\n",
        "\n",
        "print(\"Filter designed.\")"
      ],
      "metadata": {
        "id": "Jydks4CsXahV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 필터 억제 그래프 출력\n",
        "\n",
        "# plot_filter_response(b_df1, a_df1, fs_df1, \"Band-pass 0.5–6 Hz (csv1 fs)\")\n",
        "# plot_filter_response(b_df2, a_df2, fs_df2, \"Band-pass 0.5–6 Hz (csv2 fs)\")"
      ],
      "metadata": {
        "id": "9H_WT8sAXr09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================\n",
        "# 실제 필터 적용\n",
        "# =====================\n",
        "\n",
        "df1_filt = apply_bandpass(df1, b_df1, a_df1)\n",
        "df2_filt = apply_bandpass(df2, b_df2, a_df2)\n",
        "\n",
        "print(\"Filtering finished.\")\n",
        "print(\"Columns in df1:\", df1_filt.columns.tolist())\n",
        "print(\"Columns in df2:\", df2_filt.columns.tolist())"
      ],
      "metadata": {
        "id": "KdmEXmYJX0NB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================\n",
        "# 필터 통과 전후 시각화1\n",
        "# =====================\n",
        "plot_before_after(\n",
        "    df1_filt,\n",
        "    col_raw=\"ppg\",\n",
        "    col_filt=\"ppg_filt\",\n",
        "    title=\"df1 PPG\",\n",
        "    duration_sec=5\n",
        ")\n",
        "\n",
        "plot_before_after(\n",
        "    df2_filt,\n",
        "    col_raw=\"ppg\",\n",
        "    col_filt=\"ppg_filt\",\n",
        "    title=\"df2 PPG\",\n",
        "    duration_sec=5\n",
        ")"
      ],
      "metadata": {
        "id": "j7v04aCOX-cg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================\n",
        "# 필터 통과 전후 시각화2\n",
        "# =====================\n",
        "def compare_hist(df, col_raw, col_filt, title):\n",
        "    plt.figure(figsize=(10,4))\n",
        "    plt.hist(df[col_raw].values,  bins=60, alpha=0.4, label=\"Raw\")\n",
        "    plt.hist(df[col_filt].values, bins=60, alpha=0.4, label=\"Filtered\")\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"PPG value\")\n",
        "    plt.ylabel(\"Count\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "compare_hist(df1_filt, \"ppg\", \"ppg_filt\",   \"Value distribution (csv1)\")\n",
        "compare_hist(df2_filt, \"ppg\", \"ppg_filt\", \"Value distribution (csv2)\")"
      ],
      "metadata": {
        "id": "mpq95jJ6YOdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5 개 특징점으로 SVM 학습 (12.03)"
      ],
      "metadata": {
        "id": "-RUYXKmqYTbg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================\n",
        "# 필터 통과 전후 시각화2\n",
        "# =====================\n",
        "df1_features, (df1_peaks, df1_s_idx, df1_e_idx) = extract_pulse_features(\n",
        "    df1_filt,\n",
        "    fs_df1,\n",
        "    ppg_col=\"ppg_filt\",\n",
        "    label=\"esther\")\n",
        "\n",
        "df2_features, (df2_peaks, df2_s_idx, df2_e_idx) = extract_pulse_features(\n",
        "    df2_filt,\n",
        "    fs_df2,\n",
        "    ppg_col=\"ppg_filt\",\n",
        "    label=\"p1\")"
      ],
      "metadata": {
        "id": "izbH4mGrYSL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================\n",
        "# df2 features -> csv로 저장\n",
        "# =====================\n",
        "name = input(\"csv 파일 이름:\")\n",
        "df2_features.to_csv(f\"features_{name}.csv\", index=True)"
      ],
      "metadata": {
        "id": "1N15kKNlAnFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `plot_feature_hist()`\n",
        "```\n",
        "입력: (features_df, col, title)\n",
        "출력: 히스토그램 분포 시각화\n",
        "```"
      ],
      "metadata": {
        "id": "0OPYxN3kA3UZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "def plot_feature_hist(features_df, col, title):\n",
        "    plt.figure(figsize=(6,4))\n",
        "    vals = features_df[col].dropna().values\n",
        "    plt.hist(vals, bins=40, alpha=0.7)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel(\"Count\")\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Gmuq0xUCAzi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_feature_hist(df1_features, \"As\", \"Static - Systolic Amplitude (As)\")\n",
        "plot_feature_hist(df1_features, \"Pw\", \"Static - Pulse Width (Pw)\")\n",
        "plot_feature_hist(esther_features, \"Tc\", \"Static - Crest Time (Tc)\")\n",
        "plot_feature_hist(df1_features, \"Pi_over_As\", \"Static - Pi/As\")\n",
        "plot_feature_hist(df1_features, \"Ab_over_Aa\", \"Static - Ab_w / Aa_w\")"
      ],
      "metadata": {
        "id": "SucvAZp6BMhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 분포에서 너무 떨어진 데이터들 Drop"
      ],
      "metadata": {
        "id": "_UrCI3NlBS5-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================\n",
        "# 특징 분포에서 너무 떨어진 이상치 값들 제거\n",
        "# =====================\n",
        "\n",
        "cols = ['As', 'Pw', 'Pi_over_As', 'Ab_over_Aa']\n",
        "\n",
        "def iqr_filter(df, cols, k=1.5):\n",
        "    mask = np.ones(len(df), dtype=bool)\n",
        "    for c in cols:\n",
        "        q1 = df[c].quantile(0.25)\n",
        "        q3 = df[c].quantile(0.75)\n",
        "        iqr = q3 - q1\n",
        "        low  = q1 - k * iqr\n",
        "        high = q3 + k * iqr\n",
        "        mask &= df[c].between(low, high)\n",
        "    return mask\n",
        "\n",
        "# df1_features 특징점들 분포를 보고, 너무 떨어진 값들 Drop\n",
        "df_mask = iqr_filter(df1_features, cols)\n",
        "df1_clean = df1_features[df_mask].copy()\n",
        "print(df1_clean.shape)\n",
        "\n",
        "# # df2에 적용\n",
        "# df2_mask = iqr_filter(df2_features, cols)\n",
        "# df2_clean = df2_features[df2_mask].copy()"
      ],
      "metadata": {
        "id": "DOzx3OPSBPOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 특징점만 모아서 새 df 생성\n",
        "cols = ['As', 'Pw', 'Pi_over_As', 'Ab_over_Aa']\n",
        "df1_features_subset = df1_clean[cols].copy()\n",
        "print(f\"features_subset.shaep: {df1_features_subset.shape}\")\n",
        "\n",
        "# # df2에 적용\n",
        "# df2_features_subset = df2_clean[cols].copy()\n",
        "# print(df2_features_subset.shape)"
      ],
      "metadata": {
        "id": "3fhKOIrZBl8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================\n",
        "# 결측값 방지\n",
        "# =====================\n",
        "df1_features_subset = df1_features_subset.dropna().values\n",
        "# df2_features_subset = df2_features_subset.dropna().values # 결측값 버림!!!"
      ],
      "metadata": {
        "id": "-oqGJNkQDC07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 사용자 라벨(=0) 만들기"
      ],
      "metadata": {
        "id": "UksdH06NBuKG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ['label']을 만들어서 모두 0으로 채우기\n",
        "df1_features_subset['label'] = 0\n",
        "print(df1_features_subset[:10])"
      ],
      "metadata": {
        "id": "S-y7X0YYBr-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVM 교차 검증 학습"
      ],
      "metadata": {
        "id": "qiVFj3XTCDb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import KFold"
      ],
      "metadata": {
        "id": "u05XV3Y5B0Z9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================\n",
        "# SVM 하이퍼파라미터 튜닝\n",
        "# =====================\n",
        "\n",
        "# 1) 사용자 데이터만 사용 (label == 0 이라고 가정)\n",
        "user_mask = df1_features_subset['label'] == 0\n",
        "X_user = df1_features_subset[user_mask].drop(columns=['label']).values  # (N, d)\n",
        "print(\"전체 사용자 데이터:\", X_user.shape)\n",
        "\n",
        "# 교차검증 전 test셋 분리\n",
        "X_train_all, X_test = train_test_split(\n",
        "    X_user, test_size=0.2, random_state=42\n",
        ")\n",
        "print(\"train:\", X_train_all.shape, \"test:\", X_test.shape)\n",
        "\n",
        "# 2) 하이퍼파라미터 후보\n",
        "nu_list = [0.01, 0.03, 0.05, 0.07, 0.1]\n",
        "gamma_list  = ['scale', 0.1, 0.01]\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "best_score  = -np.inf\n",
        "best_params = None\n",
        "\n",
        "def predict_with_threshold(scores, thr):\n",
        "    # 1 = 정상, -1 = 이상\n",
        "    return np.where(scores >= thr, 1, -1)\n",
        "\n",
        "for nu in nu_list:\n",
        "    for gamma in gamma_list:\n",
        "        fold_scores = []\n",
        "\n",
        "        for tr_idx, val_idx in kf.split(X_train_all):\n",
        "            X_tr  = X_train_all[tr_idx]\n",
        "            X_val = X_train_all[val_idx]\n",
        "\n",
        "            # --- 각 fold마다 스케일러는 train fold 기준으로만 fit ---\n",
        "            scaler_cv = StandardScaler()\n",
        "            X_tr_sc  = scaler_cv.fit_transform(X_tr)\n",
        "            X_val_sc = scaler_cv.transform(X_val)\n",
        "\n",
        "            # --- 모델 학습 ---\n",
        "            model = OneClassSVM(kernel='rbf', nu=nu, gamma=gamma)\n",
        "            model.fit(X_tr_sc)\n",
        "\n",
        "            # --- train fold 점수 분포로 threshold (하위 5%) 설정 ---\n",
        "            train_scores = model.decision_function(X_tr_sc)\n",
        "            thr = np.percentile(train_scores, 5)\n",
        "\n",
        "            # --- val fold 평가 (모두 정상 데이터) ---\n",
        "            val_scores = model.decision_function(X_val_sc)\n",
        "            test_pred   = predict_with_threshold(val_scores, thr)\n",
        "\n",
        "            # 정상으로 나온 비율 (높을수록 좋음)\n",
        "            fold_scores.append((test_pred == 1).mean())\n",
        "\n",
        "        mean_score = np.mean(fold_scores)\n",
        "        print(f\"nu={nu}, gamma={gamma}, cv_score={mean_score:.3f}\")\n",
        "\n",
        "        if mean_score > best_score:\n",
        "            best_score  = mean_score\n",
        "            best_params = {'nu': nu, 'gamma': gamma}\n",
        "\n",
        "print(\"선택된 best_params:\", best_params, \"cv_score:\", best_score)"
      ],
      "metadata": {
        "id": "YPAHWzEtCHoj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================\n",
        "# train 데이터셋 전체로 학습\n",
        "# =====================\n",
        "\n",
        "# 3) 선택된 파라미터로 train 전체(X_train_all)에 최종 학습\n",
        "scaler = StandardScaler()\n",
        "X_train_sc = scaler.fit_transform(X_train_all)\n",
        "# X_test_sc = scaler.transform(X_test)\n",
        "\n",
        "ocsvm = OneClassSVM(kernel='rbf', **best_params)\n",
        "ocsvm.fit(X_train_sc)"
      ],
      "metadata": {
        "id": "ausm0h5CCU0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================\n",
        "# 훈련된 모델 저장\n",
        "# =====================\n",
        "\n",
        "import joblib\n",
        "\n",
        "# 예시: 이미 학습이 끝난 객체들\n",
        "# ocsvm : OneClassSVM 모델\n",
        "# scaler: StandardScaler (fit 완료 상태)\n",
        "# threshold: train_scores에서 구한 값\n",
        "\n",
        "save_obj = {\n",
        "    \"model\": ocsvm,\n",
        "    \"scaler\": scaler,\n",
        "}\n",
        "model_name = input(\"모델 이름:\")\n",
        "\n",
        "joblib.dump(save_obj, f\"{model_name}.joblib\")\n",
        "print(\"저장 완료\")"
      ],
      "metadata": {
        "id": "OTqwkANfCe7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.set_printoptions(precision=6,   # 소수점 6자리까지\n",
        "                    suppress=True) # e-05 같은 지수 표현 끄기"
      ],
      "metadata": {
        "id": "jtJq5yAACjLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================\n",
        "# decision_function 점수 확인\n",
        "# =====================\n",
        "\n",
        "train_scores = ocsvm.decision_function(X_train_sc)  # (값이 클수록 정상)\n",
        "\n",
        "X_test_sc = scaler.transform(X_test)\n",
        "test_scores = ocsvm.decision_function(X_test_sc) # 동일한 스케일러 적용 후 점수 확인\n",
        "\n",
        "print(\"train_scores min/max:\", train_scores.min(), train_scores.max())\n",
        "print(\"train_scores mean:\", train_scores.mean())\n",
        "print(\"========================\")\n",
        "print(\"val_scores min/max:\", test_scores.min(), test_scores.max())\n",
        "print(\"val_scores mean:\", test_scores.mean())"
      ],
      "metadata": {
        "id": "VAqZ2XKNCjs0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_scores)"
      ],
      "metadata": {
        "id": "ZQv2o5zaCxop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred = ocsvm.predict(X_test_sc) # 결정함수 값이 0보다 크면 1, 아니면 -1\n",
        "print(test_pred)"
      ],
      "metadata": {
        "id": "tOFGd-HWCyuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 공격자 데이터(df2) 피처로 점수 확인"
      ],
      "metadata": {
        "id": "U2nvwdzZC1_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2_features_sc = scaler.transform(df2_features_subset)\n",
        "print(\"스케일된 df2_features_sc\")\n",
        "print(df2_features_sc[:5])\n",
        "print(\"========================\")\n",
        "print(f\"피처 추출된 심주기 개수: {len(df2_features_sc)}\")"
      ],
      "metadata": {
        "id": "qZu4LTavC8EJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2_score = ocsvm.decision_function(df2_features_sc)\n",
        "print(\"val_scores min/max:\", df2_score.min(), df2_score.max())\n",
        "print(\"val_scores mean:\", df2_score.mean())\n",
        "print(df2_score.mean())\n",
        "print(\"========================\")\n",
        "print(df2_score)"
      ],
      "metadata": {
        "id": "epWz-OtdDfl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# --------------------\n",
        "# 5) 커스텀 threshold 설정\n",
        "#    예: train 데이터의 5% 지점(5번째 퍼센타일)을 이상치 경계로 사용\n",
        "# --------------------\n",
        "# threshold = np.percentile(train_scores, 5)   # 5%보다 낮으면 이상으로 간주\n",
        "\n",
        "# threshold = np.percentile(train_scores, 5)\n",
        "# print(\"threshold:\", threshold)\n",
        "\n",
        "# # 5) 진짜 test 셋 평가\n",
        "# test_pred    = predict_with_threshold(test_scores, threshold)\n",
        "\n",
        "# print(\"test에서 정상(1) 비율:\", (test_pred == 1).mean())"
      ],
      "metadata": {
        "cellView": "form",
        "id": "e0hueD6FCvBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ppg 전처리 과정 (시각화 함께)"
      ],
      "metadata": {
        "id": "R0rRBrsBFLEb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `plot_pulses_with_markers()`\n",
        "> (df, peaks, starts, ends, title, duration_sec=5)를 입력받아서 **피크, 벨리 시각화**"
      ],
      "metadata": {
        "id": "TtHFB-z9FUg5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "def plot_pulses_with_markers(df, peaks, starts, ends, title, duration_sec=5):\n",
        "    time_s = df[\"time_s\"].values\n",
        "    ppg    = df[\"ppg_filt\"].values.astype(float)\n",
        "\n",
        "    t0 = time_s[0]\n",
        "    mask = (time_s - t0) <= duration_sec\n",
        "\n",
        "    plt.figure(figsize=(12,5))\n",
        "    plt.plot(time_s[mask] - t0, ppg[mask], label=\"PPG filtered\")\n",
        "\n",
        "    # mark peaks and valleys in this window\n",
        "    for pk, s_idx, e_idx in zip(peaks, starts, ends):\n",
        "        if (s_idx is None) or (e_idx is None):\n",
        "            continue\n",
        "        t_pk = time_s[pk] - t0\n",
        "        t_s  = time_s[s_idx] - t0\n",
        "        t_e  = time_s[e_idx] - t0\n",
        "        if t_pk < 0 or t_pk > duration_sec:\n",
        "            continue\n",
        "\n",
        "        plt.plot(t_pk, ppg[pk], \"ro\", label=\"Peak\" if \"Peak\" not in plt.gca().get_legend_handles_labels()[1] else \"\")\n",
        "        plt.plot(t_s,  ppg[s_idx], \"go\", label=\"Valley\" if \"Valley\" not in plt.gca().get_legend_handles_labels()[1] else \"\")\n",
        "        plt.plot(t_e,  ppg[e_idx], \"go\")\n",
        "\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Time (s)\")\n",
        "    plt.ylabel(\"PPG (filtered)\")\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "e9-W81g0FSAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_pulses_with_markers(\n",
        "    df1_filt,\n",
        "    df1_peaks,\n",
        "    df1_s_idx,\n",
        "    df1_e_idx,\n",
        "    title=\"Static PPG with detected peaks/valleys\",\n",
        "    duration_sec=60\n",
        ")\n",
        "\n",
        "plot_pulses_with_markers(\n",
        "    df2_filt,\n",
        "    df2_peaks,\n",
        "    df2_s_idx,\n",
        "    df2_e_idx,\n",
        "    title=\"Far-wrist PPG with detected peaks/valleys\",\n",
        "    duration_sec=60\n",
        ")"
      ],
      "metadata": {
        "id": "nUptXZFgFlo1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `plot_all_pulses()`\n",
        "> (pulses, cols=10) 입력받아서 모든 심주기 찍어보기, 심주기 단위로 잘려서 150으로 리샘플된 np 배열"
      ],
      "metadata": {
        "id": "nHkX3TJPFuN4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1_pulses = extract_pulse_waveforms(df1_filt, df1_features, seq_len=150)\n",
        "df2_pulses = extract_pulse_waveforms(df2_filt, df2_features, seq_len=150)"
      ],
      "metadata": {
        "id": "Ik7_ylhxGU68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "def plot_all_pulses(pulses, cols=10):\n",
        "    \"\"\"\n",
        "    pulses: numpy array (N, seq_len)\n",
        "    cols: subplot에서 한 행에 몇 개 출력할지\n",
        "    \"\"\"\n",
        "    N, seq_len = pulses.shape\n",
        "\n",
        "    rows = math.ceil(N / cols)\n",
        "\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(cols*2, rows*2), sharex=True, sharey=True)\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for i in range(len(axes)):\n",
        "        ax = axes[i]\n",
        "        if i < N:\n",
        "            ax.plot(pulses[i])\n",
        "            ax.set_title(f\"{i}\", fontsize=8)\n",
        "            ax.set_xticks([])\n",
        "            ax.set_yticks([])\n",
        "        else:\n",
        "            ax.axis('off')   # 남는 subplot 숨기기\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "1o17Y23rFobd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df1_pulses.shape)\n",
        "plot_all_pulses(df1_pulses, cols=10)"
      ],
      "metadata": {
        "id": "x4sjfJ0pGDZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `outliers = [ ]` <- 여기에 제거할 인덱스 번호 입력"
      ],
      "metadata": {
        "id": "jnyWZ7OTGHjr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outliers = []  # 제거할 인덱스\n",
        "static_clean = np.delete(df1_pulses, outliers, axis=0)\n",
        "print(static_clean.shape)"
      ],
      "metadata": {
        "id": "ChG4WsqFGJ9G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}